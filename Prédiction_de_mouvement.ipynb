{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcb3eb39",
   "metadata": {},
   "source": [
    "# Test du mod√©le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f80fe2",
   "metadata": {},
   "source": [
    "### Importation des bibliot√©que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf7ab510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import load_model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d44823",
   "metadata": {},
   "source": [
    "### Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "554230e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation de la classe mediapipe pose.\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Configuration de la fonction Pose.\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3, model_complexity=2)\n",
    "\n",
    "# Initialisation de la classe mediapipe drawing, utile pour l'annotation.\n",
    "mp_drawing = mp.solutions.drawing_utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef03123",
   "metadata": {},
   "source": [
    "### Chargement du mod√©le et d√©finition des fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93446293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le mod√®le √† partir du fichier h5\n",
    "model = load_model('CNN1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fe767b",
   "metadata": {},
   "source": [
    "üìè Cette fonction, calculateAngle, calcule l'angle entre trois rep√®res diff√©rents sp√©cifi√©s en entr√©e et retourne cet angle en degr√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adfabee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAngle(landmark1, landmark2, landmark3):\n",
    "    '''\n",
    "    Cette fonction calcule l'angle entre trois landmarks diff√©rents.\n",
    "    Args:\n",
    "        landmark1: Le premier landmark contenant les coordonn√©es x, y et z.\n",
    "        landmark2: Le deuxi√®me landmark contenant les coordonn√©es x, y et z.\n",
    "        landmark3: Le troisi√®me landmark contenant les coordonn√©es x, y et z.\n",
    "    Returns:\n",
    "        angle: L'angle calcul√© entre les trois landmarks.\n",
    "    '''\n",
    "\n",
    "    # Obtenir les coordonn√©es des landmarks requis.\n",
    "    x1, y1, _ = landmark1\n",
    "    x2, y2, _ = landmark2\n",
    "    x3, y3, _ = landmark3\n",
    "\n",
    "    # Calculer l'angle entre les trois points.\n",
    "    angle = math.degrees(math.atan2(y3 - y2, x3 - x2) - math.atan2(y1 - y2, x1 - x2))\n",
    "    \n",
    "    # V√©rifier si l'angle est inf√©rieur √† z√©ro.\n",
    "    if angle < 0:\n",
    "\n",
    "        # Ajouter 360 √† l'angle trouv√©.\n",
    "        angle += 360\n",
    "    \n",
    "    # Renvoyer l'angle calcul√©.\n",
    "    return angle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498e830e",
   "metadata": {},
   "source": [
    "üï∫ Cette fonction, nomm√©e detectPose, a pour objectif de d√©tecter et d'analyser la pose humaine dans une image donn√©e. Elle prend en entr√©e une image, un objet de d√©tection de pose, et un param√®tre optionnel pour l'affichage. La fonction effectue la d√©tection de la pose en utilisant l'objet de pose fourni, r√©cup√®re les points de rep√®re d√©tect√©s, puis calcule une s√©rie d'angles pour diff√©rentes articulations du corps, tels que les angles des coudes, des √©paules, des hanches, des poignets, etc. Si le param√®tre d'affichage est activ√©, la fonction affiche l'image d'origine avec les annotations de la pose. En fin de compte, la fonction retourne l'image de sortie, la liste des points de rep√®re d√©tect√©s, ainsi que les angles calcul√©s pour les articulations du corps. üì∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "406b3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectPose(image, pose, display=True):\n",
    "    '''\n",
    "    Cette fonction effectue la d√©tection de la pose sur une image.\n",
    "    Args:\n",
    "        image: L'image d'entr√©e avec une personne en √©vidence dont les rep√®res de pose doivent √™tre d√©tect√©s.\n",
    "        pose: La fonction de configuration de la pose requise pour effectuer la d√©tection de la pose.\n",
    "        afficher: Une valeur bool√©enne qui, si elle est d√©finie sur True, affiche l'image d'entr√©e d'origine, l'image r√©sultante,\n",
    "                 et les rep√®res de pose dans le trac√© 3D, et ne renvoie rien.\n",
    "    Returns:\n",
    "        image_resultat: L'image d'entr√©e avec les rep√®res de pose d√©tect√©s dessin√©s.\n",
    "        rep√®res: Une liste de rep√®res d√©tect√©s convertis √† leur √©chelle d'origine.\n",
    "    '''\n",
    "    \n",
    "    # Cette fonction effectue la d√©tection de la pose sur une image.\n",
    "    output_image = image.copy()\n",
    "    \n",
    "    # Convertissez l'image de BGR en format RGB.\n",
    "    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Effectuer la d√©tection de la pose.\n",
    "    results = pose.process(imageRGB)\n",
    "    \n",
    "    # R√©cup√©rer la hauteur et la largeur de l'image d'entr√©e.\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    # Initialisez une liste pour stocker les rep√®res d√©tect√©s.\n",
    "    landmarks = []\n",
    "    \n",
    "    # V√©rifiez si des rep√®res sont d√©tect√©s.\n",
    "    if results.pose_landmarks:\n",
    "    \n",
    "        # Dessinez les rep√®res de pose sur l'image de sortie.\n",
    "        mp_drawing.draw_landmarks(image=output_image, landmark_list=results.pose_landmarks,\n",
    "                                  connections=mp_pose.POSE_CONNECTIONS)\n",
    "        \n",
    "        # It√©rer sur les rep√®res d√©tect√©s.\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            \n",
    "            # Ajoutez le rep√®re √† la liste.\n",
    "            landmarks.append((int(landmark.x * width), int(landmark.y * height),\n",
    "                                  (landmark.z * width)))\n",
    "    \n",
    "    # V√©rifiez si l'image d'entr√©e d'origine et l'image r√©sultante doivent √™tre affich√©es.\n",
    "    if display:\n",
    "    \n",
    "        # Affichez l'image d'entr√©e d'origine et l'image r√©sultante.\n",
    "        plt.figure(figsize=[22,22])\n",
    "        plt.subplot(121);plt.imshow(image[:,:,::-1]);plt.title(\"Original Image\");plt.axis('off');\n",
    "        plt.subplot(122);plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
    "        \n",
    "        # Tracez √©galement les rep√®res de pose en 3D.\n",
    "        mp_drawing.plot_landmarks(results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        \n",
    "   \n",
    "    else:\n",
    "        \n",
    "        # renvoyez l'image de sortie et les rep√®res trouv√©s.\n",
    "        return output_image, landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1042638d",
   "metadata": {},
   "source": [
    "üßò La fonction classifyPose a pour objectif de classifier les poses de boxe chinoise en fonction des angles des diff√©rentes articulations du corps d√©tect√©s. Elle prend en entr√©e une liste de points de rep√®re de la pose üìç, une image de sortie avec les points de rep√®re dessin√©s üñºÔ∏è, un mod√®le de classification ü§ñ, une liste de cat√©gories de poses üìã, ainsi qu'un param√®tre optionnel de visualisation üëÅÔ∏è.\n",
    "\n",
    "üîÑ Initialement, la fonction initialise l'√©tiquette de la pose √† \"Unknown Pose\" (pose inconnue) ‚ùì et d√©finit la couleur pour √©crire l'√©tiquette sur l'image (rouge üî¥).\n",
    "\n",
    "üìè Ensuite, elle calcule une s√©rie d'angles entre les articulations du corps, tels que les angles des coudes, des √©paules, des hanches, des poignets, etc. Ces angles sont calcul√©s √† partir des points de rep√®re d√©tect√©s dans la pose.\n",
    "\n",
    "üìä La fonction pr√©pare ensuite les donn√©es des angles calcul√©s dans un format adapt√© pour la classification, puis pr√©dit la pose √† l'aide du mod√®le de classification.\n",
    "\n",
    "üéØ Si la pr√©diction d√©passe un certain seuil de confiance (0,95 dans cet exemple), l'√©tiquette de la pose est mise √† jour en fonction de la pr√©diction du mod√®le.\n",
    "\n",
    "üñãÔ∏è Enfin, la fonction √©crit l'√©tiquette de la pose sur l'image de sortie, en utilisant la couleur appropri√©e en fonction du succ√®s de la classification.\n",
    "\n",
    "üñºÔ∏è Lorsque le param√®tre display est d√©fini sur True, l'image r√©sultante est affich√©e. Sinon, l'image de sortie et l'√©tiquette de la pose classifi√©e sont renvoy√©es en sortie de la fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0da9c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyPose(landmarks, output_image, model,categories, display=False):\n",
    "    '''\n",
    "    Cette fonction classifie les poses de yoga en fonction des angles des diff√©rentes articulations du corps.\n",
    "    Args:\n",
    "        landmarks: Une liste de rep√®res d√©tect√©s de la personne dont la pose doit √™tre classifi√©e.\n",
    "        output_image: Une image de la personne avec les rep√®res de pose d√©tect√©s dessin√©s.\n",
    "        afficher: Une valeur bool√©enne qui, si elle est d√©finie sur True, affiche l'image r√©sultante avec l'√©tiquette de pose\n",
    "                 √©crite dessus et ne renvoie rien.\n",
    "    Returns:\n",
    "        output_image: L'image avec les rep√®res de pose d√©tect√©s dessin√©s et l'√©tiquette de pose √©crite.\n",
    "        label: L'√©tiquette de pose classifi√©e de la personne dans l'image de sortie.\n",
    "    '''\n",
    "    \n",
    "    # Initialiser l'√©tiquette de la pose. Elle n'est pas connue √† ce stade.\n",
    "    label = 'Unknown Pose'\n",
    "\n",
    "    # Sp√©cifier la couleur (rouge) avec laquelle l'√©tiquette sera √©crite sur l'image.\n",
    "    color = (0, 0, 255)\n",
    "    \n",
    "    # Calculer les angles n√©cessaires.\n",
    "    #----------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "# Calculer les angles articulaires pour chaque ligne dans le DataFrame.\n",
    "\n",
    "    # Calculer les angles des articulations\n",
    "    # Obtenir l'angle entre les points d'√©paule gauche, de coude gauche et de poignet gauche.\n",
    "    elbow_left_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
    "\n",
    "    # Obtenir l'angle entre les points d'√©paule droite, de coude droit et de poignet droit.\n",
    "    elbow_right_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value])\n",
    "\n",
    "    # Obtenir l'angle entre les points de hanche gauche, d'√©paule gauche et de coude gauche.\n",
    "    shoulder_left_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                         landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                         landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value])\n",
    "\n",
    "    # Obtenir l'angle entre les points de hanche droite, d'√©paule droite et de coude droit.\n",
    "    shoulder_right_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n",
    "    \n",
    "\n",
    "    # Obtenir l'angle entre les points de hanche gauche, de genou gauche et de cheville gauche.\n",
    "    hip_left_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                    landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                    landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value])\n",
    "\n",
    "    # Obtenir l'angle entre les points de hanche droite, de genou droit et de cheville droite.\n",
    "    hip_right_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n",
    "\n",
    "    # Obtenir l'angle entre les points de coude gauche, de poignet gauche et de petit doigt gauche.\n",
    "    wrist_left_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_PINKY.value])\n",
    "\n",
    "    # Obtenir l'angle entre les points de coude droit, de poignet droit et de petit doigt droit.\n",
    "    wrist_right_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_PINKY.value])\n",
    "    \n",
    "    # Obtenir l'angle entre les points de hanche droit, de √©pole gauche et de coude gauche.\n",
    "    shoulder_lateral_left_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value])\n",
    "    \n",
    "    # Obtenir l'angle entre les points de hanche gauche, de √©pole droit et de coude droit.\n",
    "    shoulder_lateral_right_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n",
    "    \n",
    "     # Obtenir l'angle entre les points de hanche droit, de √©pole gauche et de coude gauche.\n",
    "    shoulder_lateral2_left_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value])\n",
    "    \n",
    "    # Obtenir l'angle entre les points de hanche gauche, de √©pole droit et de coude droit.\n",
    "    shoulder_lateral2_right_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n",
    "    \n",
    "    \n",
    "    # Obtenir l'angle entre les points de pouce gauche, de poignet gauche et de petit doigt gauche.\n",
    "    hand_left_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_THUMB.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.LEFT_PINKY.value])\n",
    "    \n",
    "    # Obtenir l'angle entre les points de pouce droit, de poignet droit et de petit doigt droit.\n",
    "    hand_right_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_THUMB.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_PINKY.value])\n",
    "    \n",
    "    # Obtenir l'angle entre les points de pouce gauche, de poignet gauche et de coude gauche.\n",
    "    hand_lateral_left_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_THUMB.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value])\n",
    "    \n",
    "    # Obtenir l'angle entre les points de pouce droit, de poignet droit et de coude droit.\n",
    "    hand_lateral_right_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_THUMB.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n",
    "    \n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "    dic = {'Angles_Elbow_Right':[elbow_right_angle],\n",
    "                        'Angles_Elbow_Left': [elbow_left_angle],\n",
    "                        'Angles_Shoulder_Right': [shoulder_right_angle],\n",
    "                        'Angles_Shoulder_Left': [shoulder_left_angle],\n",
    "                        'Angles_Hip_Right': [hip_right_angle],\n",
    "                        'Angles_Hip_Left': [hip_left_angle],\n",
    "                        'Angles_Wrist_Right': [wrist_right_angle],\n",
    "                        'Angles_Wrist_Left':[wrist_left_angle],\n",
    "                        'Angles_Shoulder_lateral_Left': [shoulder_lateral_left_angle],\n",
    "                        'Angles_Shoulder_lateral_right': [shoulder_lateral_right_angle],\n",
    "                        'Angles_Shoulder_lateral2_Left': [shoulder_lateral2_left_angle],\n",
    "                        'Angles_Shoulder_lateral2_right': [shoulder_lateral2_right_angle],\n",
    "                        'Angles_Hand_Left': [hand_left_angle],\n",
    "                        'Angles_Hand_right': [hand_right_angle],\n",
    "                        'Angles_Hand_lateral_Left': [hand_lateral_left_angle],\n",
    "                        'Angles_Hand_lateral_right': [hand_lateral_right_angle]}\n",
    "    \n",
    "    new_data = pd.DataFrame(dic)\n",
    "        #---------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    # Pr√©dire de nouvelles positions\n",
    "    predictions = model.predict(new_data)\n",
    "    \n",
    "    best_prediction_index = np.argmax(predictions)\n",
    "    best_prediction_label = categories[best_prediction_index]\n",
    "    best_prediction_value = np.max(predictions)\n",
    "\n",
    "    if best_prediction_value > 0.95:\n",
    "        label = best_prediction_label\n",
    "        \n",
    "    #----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # V√©rifier si la pose est classifi√©e avec succ√®s\n",
    "    if label != 'Unknown Pose':\n",
    "\n",
    "        # Mettre √† jour la couleur (en vert) avec laquelle l'√©tiquette sera √©crite sur l'image.\n",
    "        color = (0,255,0)  \n",
    "\n",
    "    # √âcrire l'√©tiquette sur l'image de sortie. \n",
    "    cv2.putText(output_image, label, (10, 30),cv2.FONT_HERSHEY_PLAIN, 2, color, 5)\n",
    "\n",
    "    # V√©rifier si l'image r√©sultante doit √™tre affich√©e.\n",
    "    if display:\n",
    "\n",
    "        # Afficher l'image r√©sultante..\n",
    "        plt.figure(figsize=[10,10])\n",
    "        plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Renvoyer l'image de sortie et l'√©tiquette classifi√©e.\n",
    "        return output_image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75f4a15",
   "metadata": {},
   "source": [
    "üßæ Ce code charge un LabelEncoder √† partir d'un fichier (dans ce cas, 'label_encoder.pkl') √† l'aide du module pickle üì¶. Un LabelEncoder est couramment utilis√© pour convertir des √©tiquettes de texte en √©tiquettes num√©riques pour √™tre utilis√© dans des mod√®les de machine learning ü§ñ.\n",
    "\n",
    "üì• Apr√®s avoir charg√© le LabelEncoder, le code obtient la liste des noms de cat√©gories √† partir des classes du LabelEncoder üìÉ. Ces noms de cat√©gories sont g√©n√©ralement des √©tiquettes textuelles qui correspondent aux classes num√©riques üìä."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24f4d2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bong_Sau_L', 'Bong_Sau_R', 'Double_Biu_Sau', 'Double_Bui_Sau', 'Double_Fak_Sau', 'Double_Forward_Palm', 'Double_Forward_Palm_prep', 'Double_Gan_Sau', 'Double_Gum_Sau', 'Double_Huan_Sau', 'Double_Huen_Sau', 'Double_Jam_Sau', 'Double_Jut_Sau', 'Double_Jut_Sau_0', 'Double_Jut_Sau_1', 'Double_Kwan_Sau', 'Double_Lan_Sau_L', 'Double_Lan_Sau_R', 'Double_Rear_Palm', 'Double_Rear_Palm/Double_Forward_Palm', 'Double_Tai_Sau', 'Double_Tan_Sau', 'Double_Tok_Sau', 'Double_Tok_Sau_0', 'Double_Tok_Sau_1', 'Down_Low_Palm_L', 'Down_Low_Palm_R', 'Fook_Sau_L', 'Fook_Sau_R', 'Gan_Sau_L', 'Gum_Sau', 'Gum_Sau_L', 'Gum_Sau_L+Gum_Sau_R', 'Gwat_Sau_L', 'Gwat_Sau_L_m', 'Gwat_Sau_R', 'Gwat_Sau_R_m', 'Hight_Low_Palm_L', 'Hight_Low_Palm_R', 'Huen_Sau_L', 'Huen_Sau_R', 'Jam_Sau_L', 'Jam_Sau_R', 'Lau_Sao_L', 'Lau_Sao_R', 'Low_Sau_L', 'Low_Sau_R', 'Low_Side_Palm_L', 'Low_Side_Palm_R', 'Make_Fist_L', 'Make_Fist_R', 'Pak_Sau_L', 'Pak_Sau_R', 'Palm Strike', 'Palm_Strike_L', 'Palm_Strike_R', 'Punch_L', 'Punch_R', 'Side_Palm_L', 'Side_Palm_R', 'Start_position', 'Tan_Sau_L', 'Tan_Sau_R', 'Tut_Sau', 'Tut_Sau ', 'Tut_Sau_L', 'Wu_Sau_L', 'Wu_Sau_R']\n"
     ]
    }
   ],
   "source": [
    "# Charger le LabelEncoder √† partir du fichier\n",
    "with open('label_encoder.pkl', 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "    \n",
    "# Obtention de la liste des noms de cat√©gories\n",
    "categories = label_encoder.classes_.tolist()\n",
    "\n",
    "# Affichage des noms de cat√©gories\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fc22fe",
   "metadata": {},
   "source": [
    "# WEBCAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feea37d",
   "metadata": {},
   "source": [
    "üìπ Ce code utilise la biblioth√®que OpenCV pour capturer la vid√©o en temps r√©el √† partir de la webcam üé• et classer la pose d'une personne. Voici comment il fonctionne :\n",
    "\n",
    "üîÑ Une fonction detectAndClassifyPose est d√©finie pour d√©tecter et classifier la pose dans chaque image captur√©e depuis la webcam. La fonction prend en entr√©e l'image captur√©e (frame), l'objet de d√©tection de pose (pose), et les mod√®les de classification (model) et les cat√©gories (categories) pour classer la pose.\n",
    "\n",
    "üì∑ La boucle principale commence en utilisant cv2.VideoCapture(0) pour capturer la vid√©o √† partir de la webcam de l'ordinateur. La cam√©ra est identifi√©e par l'indice 0, ce qui signifie la premi√®re cam√©ra d√©tect√©e.\n",
    "\n",
    "üîÑ √Ä chaque it√©ration de la boucle, une image est captur√©e √† partir de la webcam √† l'aide de cap.read(), et la fonction detectAndClassifyPose est appel√©e pour d√©tecter et classifier la pose dans cette image.\n",
    "\n",
    "üéØ La classification de la pose est r√©alis√©e en utilisant le mod√®le de classification (model) et les cat√©gories (categories) charg√©s pr√©c√©demment.\n",
    "\n",
    "üñ•Ô∏è L'image avec la pose classifi√©e est affich√©e dans une fen√™tre nomm√©e \"Pose Classification\" √† l'aide de cv2.imshow.\n",
    "\n",
    "üõë La boucle continue √† s'ex√©cuter jusqu'√† ce que la touche 'q' soit press√©e. Lorsque 'q' est press√©, la boucle se termine, et les ressources de la webcam sont lib√©r√©es avec cap.release() et toutes les fen√™tres OpenCV sont ferm√©es avec cv2.destroyAllWindows()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af55addb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Fonction pour d√©tecter et classifier la pose\n",
    "def detectAndClassifyPose(frame, pose):\n",
    "    output_image, landmarks = detectPose(frame, pose, display=False)\n",
    "    if landmarks:\n",
    "        classifyPose(landmarks, output_image, model, categories, display=False)\n",
    "    cv2.imshow(\"Pose Classification\", output_image)\n",
    "\n",
    "# Capture vid√©o √† partir de la webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Boucle principale pour lire les images de la webcam\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Appeler la fonction pour d√©tecter et classifier la pose sur chaque image\n",
    "    detectAndClassifyPose(frame, pose)\n",
    "\n",
    "    # Sortir de la boucle si la touche 'q' est press√©e\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Lib√©rer les ressources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc9e40",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "666e5f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Fonction pour d√©tecter et classifier la pose\n",
    "def detectAndClassifyPose(frame, pose):\n",
    "    output_image, landmarks = detectPose(frame, pose, display=False)\n",
    "    if landmarks:\n",
    "        classifyPose(landmarks, output_image, model, categories, display=False)\n",
    "    cv2.imshow(\"Pose Classification\", output_image)\n",
    "\n",
    "# Capture vid√©o √† partir de la webcam\n",
    "cap = cv2.VideoCapture('../video/Siu Nim Tau/test/Siu Nim Tau Summary (Ë©†Êò•Â∞èÂøµÈ†≠).mp4')\n",
    "\n",
    "# Boucle principale pour lire les images de la webcam\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Appeler la fonction pour d√©tecter et classifier la pose sur chaque image\n",
    "    detectAndClassifyPose(frame, pose)\n",
    "\n",
    "    # Sortir de la boucle si la touche 'q' est press√©e\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Lib√©rer les ressources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc81ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
